下面给出一个符合要求的实验报告书模板，内容涵盖各部分所需内容，供参考：

---

# 实验报告书

## 一、实验内容

本次实验的主题为 **Rust单词拼装分类器**。实现要求如下：  
1. 对Rust源代码中的各类单词（记号）进行拼装和分类。单词类型包括：  
   - 标识符、关键字  
   - 数字字面量（整数、浮点数，包括二进制、十进制、八进制和十六进制格式）  
   - 字符串字面量  
   - 注释  
   - 分隔符  
   - 运算符等  
2. 实现一个图形化Windows应用，实现文件对话框打开Rust源文件，并在对话框中列出所有可拼装的单词及其对应分类。  
3. 使用 C++编程语言进行实现，要求按照软件工程规范设计、实现及测试。  
4. 组织完备的测试数据，确保所有单词类型均得到充分测试。  
5. 参照 Rust 单词拼装规则（详细说明参见 [Rust Tokens文档](https://rustwiki.org/zh-CN/reference/tokens.html)）。

---

## 二、实验目的

本实验旨在通过实现Rust单词拼装分类器，达到以下目的：  
- 熟悉编译原理中词法分析的基本流程和技术。  
- 掌握C++语言在实际项目中的应用，并通过工程化方式开发图形界面应用。  
- 了解Rust语言的标记（token）种类及其拼装规则，提升对编译原理相关概念的认知。  
- 培养学生对项目需求分析、设计、编码和测试完整生命周期管理的能力。

---

## 三、实验文档

### 1. 项目整体架构

本项目采用模块化设计，主要模块包括：  
- **词法分析器模块（RustLexer）**  
  负责接收Rust源代码，对代码内容进行扫描并按照规则识别出不同类型的单词。  
- **界面显示模块**  
  利用Qt库构建Windows界面，包含文件打开对话框和展示分析结果的控件。  
- **测试模块**  
  构建测试用例，覆盖各类单词的情况，确保词法分析准确率。

整体流程图如下：

```
+-----------------------------+
|      用户启动程序         |
+-------------+---------------+
              |
              v
+-----------------------------+
|   图形界面：文件选择对话框  |
+-------------+---------------+
              |
              v
+-----------------------------+
|   读取并传输Rust源代码      |
+-------------+---------------+
              |
              v
+-----------------------------+
|     RustLexer词法分析器    |
|（识别标识符、关键字、数字、  |
| 字符串、注释、分隔符及操作符）|
+-------------+---------------+
              |
              v
+-----------------------------+
| 将分析结果分类后显示在界面  |
+-----------------------------+
```

### 2. 数据结构与关键算法

- **Token结构**  
  定义单词结构体 Token，包含词素字符串、单词类型、行号和列号信息，用于记录词法分析器扫描出的各类单词。

- **词法分析器类 RustLexer**  
  核心函数包括：  
  - `tokenize()`: 主函数，通过不断调用 `scanToken()` 读取并生成单词序列。  
  - `scanToken()`: 按照预定义规则（如数字、字符串、标识符、注释、运算符或分隔符等）进行判断。  
  - 辅助函数如 `peek()`, `advance()`, `isAtEnd()` 等用于辅助字符扫描。  

- **运算符和分隔符映射**  
  采用 `std::unordered_map` 存储所有支持的运算符和分隔符，便于快速匹配和分类。

- **识别数字字面量**  
  针对整数和浮点数进行了细致处理，包括对下划线分隔符、二进制、八进制、十六进制和科学计数法的支持。

- **图形用户界面**  
  使用 Qt Widgets 构建Windows平台界面，主要组件包括：  
  - 文件打开对话框，用于选择Rust源文件。  
  - 文本编辑框，用于显示文件内容。  
  - 分析结果展示区域，将词法分析后的单词及对应类别以格式化的方式展示。

### 3. 设计方案说明

- **模块划分**  
  功能逻辑主要划分为两个部分，词法分析与界面显示，二者通过数据传递接口（传入源代码文本、返回Token列表）进行解耦，便于独立测试和维护。  

- **错误处理**  
  词法分析器在遇到不合法的词素时，会生成类型为 UNKNOWN 的Token，并在分析结束后通过界面给出错误提示信息。

- **关键算法**  
  操作符识别采用贪心匹配策略，首先尝试匹配最长的运算符，然后回退减少字符数，确保正确的运算符识别。字符串和数字的识别也采用了状态机的方式，保证对转义字符和下划线格式的处理正确。

### 4. 实现与测试

- **实现过程**  
  根据需求，先搭建基本项目结构，分离界面与词法分析模块；随后完成RustLexer的各个单词识别方法的实现，并利用已有的 C++ STL 容器完成运算符、关键字等数据的存储。  
- **测试数据**  
  测试数据选用了课程提供的示例Rust代码，包括：  
  ```rust
  fn main() {
      let max_iterations = 1_000_000; // 设置迭代次数
      let mut denominator = 1; // 分母初始化为1
      let mut pi_approx = 0.0; // 初始化pi的近似值
      let mut sign = 1.0; // 初始化符号为正
       
      for _ in 0..max_iterations {
          pi_approx += sign * 4.0 / denominator;
          denominator += 2; // 分母递增2
          sign = -sign; // 符号变号
      }
       
      let pi = pi_approx * 2.0; // 最终的pi值是近似值乘以2
      println!("计算得到的pi值是: {}", pi);
  
      let hex_number = 0x1A3F_CDEF;
      let number1 =98_222;
  }
  ```
  涵盖了关键字、标识符、数字（包括下划线分隔）、注释、字符串和运算符等情况。  
- **测试结果**  
  程序在识别和分类时能正确区分各类单词，输出的结果与预期一致。

---

## 四、实验总结（心得体会）

通过本次实验，我对编译原理中词法分析的实现有了更深入的理解。实验过程让我意识到：  
- 设计一个高内聚、低耦合的模块结构对项目的可维护性和测试有重要作用。  
- 使用状态机和贪心算法处理输入字符流时，需要仔细处理边界条件和不合法输入。  
- 图形界面与后端逻辑的分离使得整个程序结构更加清晰，也便于今后的功能扩展。  

整个实验不仅加深了我对C++编程实践的理解，同时也提高了我对软件工程规范（需求、设计、实现、测试）的认识。

---

## 五、参考文献

1. Rust官方参考文档 – [Rust Tokens](https://rustwiki.org/zh-CN/reference/tokens.html)  
2. 编译原理相关教材与资料  
3. Qt官方文档与示例代码

---
